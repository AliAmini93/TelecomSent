{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-ABSA Random Forest Model using word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the reviews "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries for preprocessing the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.models import Word2Vec, word2vec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the training dataset into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20061</th>\n",
       "      <td>1168227041763823616</td>\n",
       "      <td>mtnugwhy did you disconnect my line from network</td>\n",
       "      <td>mtn - General</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20062</th>\n",
       "      <td>1168227041763823616</td>\n",
       "      <td>mtnugwhy did you disconnect my line from network</td>\n",
       "      <td>mtn - Network</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                          sentence1  \\\n",
       "20061  1168227041763823616  mtnugwhy did you disconnect my line from network    \n",
       "20062  1168227041763823616  mtnugwhy did you disconnect my line from network    \n",
       "\n",
       "           sentence2 label  \n",
       "20061  mtn - General  None  \n",
       "20062  mtn - Network  None  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = 'D:/Generate_Data/data/5_aspects/'\n",
    "df_train = pd.read_csv(os.path.join(data_dir, \"train_NLI.tsv\"),sep=\"\\t\")\n",
    "df_dev = pd.read_csv(os.path.join(data_dir, \"train_NLI.tsv\"),sep=\"\\t\")\n",
    "df_test = pd.read_csv(os.path.join(data_dir, \"test_NLI.tsv\"),sep=\"\\t\")\n",
    "df_train.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                 1095557109549359104\n",
       "sentence1    how much data is in airtelug s gb sleepy \n",
       "sentence2                     airtel - CustomerService\n",
       "label                                             None\n",
       "Name: 3000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [df_train, df_dev, df_test]\n",
    "combined_dataframe = pd.concat(frames)\n",
    "combined_dataframe.iloc[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5664</th>\n",
       "      <td>1168162668429139968</td>\n",
       "      <td>mtn whenever i get to bbunga the network start...</td>\n",
       "      <td>mtn - Calls</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665</th>\n",
       "      <td>1168162668429139968</td>\n",
       "      <td>mtn whenever i get to bbunga the network start...</td>\n",
       "      <td>mtn - CustomerService</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>1168162668429139968</td>\n",
       "      <td>mtn whenever i get to bbunga the network start...</td>\n",
       "      <td>mtn - Data</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>1168162668429139968</td>\n",
       "      <td>mtn whenever i get to bbunga the network start...</td>\n",
       "      <td>mtn - General</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>1168162668429139968</td>\n",
       "      <td>mtn whenever i get to bbunga the network start...</td>\n",
       "      <td>mtn - Network</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                          sentence1  \\\n",
       "5664  1168162668429139968  mtn whenever i get to bbunga the network start...   \n",
       "5665  1168162668429139968  mtn whenever i get to bbunga the network start...   \n",
       "5666  1168162668429139968  mtn whenever i get to bbunga the network start...   \n",
       "5667  1168162668429139968  mtn whenever i get to bbunga the network start...   \n",
       "5668  1168162668429139968  mtn whenever i get to bbunga the network start...   \n",
       "\n",
       "                  sentence2     label  \n",
       "5664            mtn - Calls      None  \n",
       "5665  mtn - CustomerService      None  \n",
       "5666             mtn - Data      None  \n",
       "5667          mtn - General      None  \n",
       "5668          mtn - Network  Negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dataframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataframe['concatinated'] = combined_dataframe['sentence1'] + ' ' + combined_dataframe['sentence2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_training_dataset = combined_dataframe['concatinated'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert each review in the training set to a list of sentences where each sentence is in turn a list of words.\n",
    "Besides splitting reviews into sentences, non-letters and stop words are removed and all words\n",
    "coverted to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_wordlist(review, remove_stopwords=True):\n",
    "    \"\"\"\n",
    "    Convert a review to a list of words.\n",
    "    \"\"\"\n",
    "    # remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review)\n",
    "    \n",
    "    # convert to lower case and split at whitespace\n",
    "    words = review_text.lower().split()\n",
    "    \n",
    "    # remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the punkt tokenizer used for splitting reviews into sentences\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_to_sentences(review, tokenizer, remove_stopwords=True):\n",
    "    \"\"\"\n",
    "    Split review into list of sentences where each sentence is a list of words.\n",
    "    \"\"\"\n",
    "    # use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "\n",
    "    # each sentence is furthermore split into words\n",
    "    sentences = []    \n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(review_to_wordlist(raw_sentence, remove_stopwords))\n",
    "            \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = []  # Initialize an empty list of sentences\n",
    "for review in word2vec_training_dataset:\n",
    "    train_sentences += review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'train_model'\n",
    "# Set values for various word2vec parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 40   # Minimum word count                        \n",
    "num_workers = 3       # Number of threads to run in parallel\n",
    "context = 10          # Context window size\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "if not os.path.exists(model_name): \n",
    "    # Initialize and train the model (this will take some time)\n",
    "    model = word2vec.Word2Vec(train_sentences, workers=num_workers, \\\n",
    "                size=num_features, min_count = min_word_count, \\\n",
    "                window = context, sample = downsampling)\n",
    "\n",
    "    # If you don't plan to train the model any further, calling \n",
    "    # init_sims will make the model much more memory-efficient.\n",
    "    model.init_sims(replace=True)\n",
    "\n",
    "    # It can be helpful to create a meaningful model name and \n",
    "    # save the model for later use. You can load it later using Word2Vec.load()\n",
    "    model.save(model_name)\n",
    "else:\n",
    "    model = Word2Vec.load(model_name)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('kla', 0.6493709087371826),\n",
       " ('extremely', 0.6402525305747986),\n",
       " ('cry', 0.6238170862197876),\n",
       " ('ug', 0.6131152510643005),\n",
       " ('brought', 0.610197901725769),\n",
       " ('z', 0.6041684746742249),\n",
       " ('edge', 0.5958809852600098),\n",
       " ('upload', 0.5940711498260498),\n",
       " ('hardly', 0.5938520431518555),\n",
       " ('super', 0.5913786888122559)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"internet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20063, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of the data\n",
    "\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the labels of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['label'].replace(['None','Positive','Negative'],[1,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [x for x in df_train.columns if x != 'label']\n",
    "\n",
    "# Split the data into two dataframes (one for the labels and the other for the independent variables)\n",
    "X_data = df_train[x_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20058</th>\n",
       "      <td>1168227041763823616</td>\n",
       "      <td>mtnugwhy did you disconnect my line from network</td>\n",
       "      <td>mtn - Calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20059</th>\n",
       "      <td>1168227041763823616</td>\n",
       "      <td>mtnugwhy did you disconnect my line from network</td>\n",
       "      <td>mtn - CustomerService</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20060</th>\n",
       "      <td>1168227041763823616</td>\n",
       "      <td>mtnugwhy did you disconnect my line from network</td>\n",
       "      <td>mtn - Data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20061</th>\n",
       "      <td>1168227041763823616</td>\n",
       "      <td>mtnugwhy did you disconnect my line from network</td>\n",
       "      <td>mtn - General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20062</th>\n",
       "      <td>1168227041763823616</td>\n",
       "      <td>mtnugwhy did you disconnect my line from network</td>\n",
       "      <td>mtn - Network</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id                                          sentence1  \\\n",
       "20058  1168227041763823616  mtnugwhy did you disconnect my line from network    \n",
       "20059  1168227041763823616  mtnugwhy did you disconnect my line from network    \n",
       "20060  1168227041763823616  mtnugwhy did you disconnect my line from network    \n",
       "20061  1168227041763823616  mtnugwhy did you disconnect my line from network    \n",
       "20062  1168227041763823616  mtnugwhy did you disconnect my line from network    \n",
       "\n",
       "                   sentence2  \n",
       "20058            mtn - Calls  \n",
       "20059  mtn - CustomerService  \n",
       "20060             mtn - Data  \n",
       "20061          mtn - General  \n",
       "20062          mtn - Network  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'africellug your internet is so frustrating pout  africell - Network'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data['concatinated'] = X_data['sentence1'] + ' ' + X_data['sentence2']\n",
    "\n",
    "X_data['concatinated'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'its a crazy weekend with africellug gb for ugx day gb for ugx days dial to activate you go kill me woawith these pretty internet bundles  africell - Network'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_data['concatinated'].values\n",
    "\n",
    "X_train[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build classifier using word embedding\n",
    "\n",
    "\n",
    "\n",
    "Each review is mapped to a feature vector by averaging the word embeddings of all words in the review. These features are then fed into a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vec(words, model, num_features):\n",
    "    \"\"\"\n",
    "    Average the word vectors for a set of words\n",
    "    \"\"\"\n",
    "    feature_vec = np.zeros((num_features,),dtype=\"float32\")  # pre-initialize (for speed)\n",
    "    nwords = 0\n",
    "    #index2word_set = set(model.index2word)  # words known to the model\n",
    "    index2word_set = set(model.wv.index2word)  # words known to the model\n",
    "    \n",
    "    \n",
    "\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1\n",
    "            feature_vec = np.add(feature_vec,model[word])\n",
    "    \n",
    "    feature_vec = np.divide(feature_vec, nwords)\n",
    "    return feature_vec\n",
    "\n",
    "\n",
    "def get_avg_feature_vecs(reviews, model, num_features):\n",
    "    \"\"\"\n",
    "    Calculate average feature vectors for all reviews\n",
    "    \"\"\"\n",
    "    counter = 0\n",
    "    review_feature_vecs = np.zeros((len(reviews),num_features), dtype='float32')  # pre-initialize (for speed)\n",
    "    \n",
    "    for review in reviews:\n",
    "        review_feature_vecs[counter] = make_feature_vec(review, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return review_feature_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# calculate average feature vectors for training and test sets\n",
    "clean_train_reviews = []\n",
    "\n",
    "for review in X_train:\n",
    "    clean_train_reviews.append(review_to_wordlist(review, remove_stopwords=True))\n",
    "    \n",
    "    \n",
    "trainDataVecs = get_avg_feature_vecs(clean_train_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit a random forest classifier to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a random forest to labeled training data...\n",
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fit a random forest to the training data, using 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "print(\"Fitting a random forest to labeled training data...\")\n",
    "forest = forest.fit(trainDataVecs, y_train)\n",
    "\n",
    "print('Completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gb for compared to gb for k good bye mtn hello africellug  africell - Calls'\n",
      " 'gb for compared to gb for k good bye mtn hello africellug  africell - CustomerService'\n",
      " 'gb for compared to gb for k good bye mtn hello africellug  africell - Data'\n",
      " 'gb for compared to gb for k good bye mtn hello africellug  africell - General'\n",
      " 'gb for compared to gb for k good bye mtn hello africellug  africell - Network'\n",
      " 'africellug some of us dont just get excited most especially when it comes to ott it used to be ugx gb but now mb for ugx mbu plus free ott not among the excited a sure nothing is free of charge in ug apart from death  africell - Calls'\n",
      " 'africellug some of us dont just get excited most especially when it comes to ott it used to be ugx gb but now mb for ugx mbu plus free ott not among the excited a sure nothing is free of charge in ug apart from death  africell - CustomerService'\n",
      " 'africellug some of us dont just get excited most especially when it comes to ott it used to be ugx gb but now mb for ugx mbu plus free ott not among the excited a sure nothing is free of charge in ug apart from death  africell - Data']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100    1\n",
       "101    1\n",
       "102    2\n",
       "103    1\n",
       "104    1\n",
       "105    1\n",
       "106    1\n",
       "107    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into two dataframes (one for the labels and the other for the independent variables)\n",
    "x_cols = [x for x in df_test.columns if x != 'label']\n",
    "X_data_test = df_test[x_cols]\n",
    "\n",
    "# Combining the review with the generated auxilliary sentence\n",
    "X_data_test['concatinated'] = X_data_test['sentence1'] + ' ' + X_data_test['sentence2']\n",
    "\n",
    "\n",
    "# X test data\n",
    "X_test = X_data_test['concatinated'].values\n",
    "\n",
    "print(X_test[100:108])\n",
    "\n",
    "\n",
    "# y test data\n",
    "y_test = df_test['label'].replace(['None','Positive','Negative'],[1,2,0])\n",
    "\n",
    "y_test[100:108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "clean_test_reviews = []\n",
    "for review in X_test:\n",
    "    clean_test_reviews.append(review_to_wordlist(review, remove_stopwords=True))\n",
    "testDataVecs = get_avg_feature_vecs(clean_test_reviews, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove instances in test set that could not be represented as feature vectors\n",
    "nan_indices = list({x for x,y in np.argwhere(np.isnan(testDataVecs))})\n",
    "if len(nan_indices) > 0:\n",
    "    print('Removing {:d} instances from test set.'.format(len(nan_indices)))\n",
    "    testDataVecs = np.delete(testDataVecs, nan_indices, axis=0)\n",
    "    test_reviews.drop(test_reviews.iloc[nan_indices, :].index, axis=0, inplace=True)\n",
    "    assert testDataVecs.shape[0] == len(test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for test data..\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting labels for test data..\")\n",
    "Y_predicted = forest.predict(testDataVecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8186629035103192\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics  import accuracy_score\n",
    "print(accuracy_score(y_test, Y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18, 0.8 , 0.02],\n",
       "       [0.15, 0.83, 0.02],\n",
       "       [0.13, 0.82, 0.05],\n",
       "       ...,\n",
       "       [0.09, 0.9 , 0.01],\n",
       "       [0.07, 0.89, 0.04],\n",
       "       [0.1 , 0.88, 0.02]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_forest_score = forest.predict_proba(testDataVecs)\n",
    "Y_forest_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Open/Create a file to append data\n",
    "csvFile_pred = open('prediction_score.csv', 'w')\n",
    "\n",
    "#Use csv Writer\n",
    "csvWriter_pred = csv.writer(csvFile_pred)\n",
    "\n",
    "csvWriter_pred.writerow(['predicted','score_none','score_pos','score_neg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(len(Y_predicted)):\n",
    "    csvWriter_pred.writerow([Y_predicted[f],Y_forest_score[f][1], Y_forest_score[f][0], Y_forest_score[f][2]])\n",
    "csvFile_pred.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>score_none</th>\n",
       "      <th>score_pos</th>\n",
       "      <th>score_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5659</th>\n",
       "      <td>1</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5660</th>\n",
       "      <td>1</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5661</th>\n",
       "      <td>0</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5662</th>\n",
       "      <td>1</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5663</th>\n",
       "      <td>1</td>\n",
       "      <td>0.610</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5664</th>\n",
       "      <td>1</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5665</th>\n",
       "      <td>1</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5666</th>\n",
       "      <td>1</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5667</th>\n",
       "      <td>1</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5668</th>\n",
       "      <td>1</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      predicted  score_none  score_pos  score_neg\n",
       "5659          1       0.650      0.260       0.09\n",
       "5660          1       0.610      0.360       0.03\n",
       "5661          0       0.430      0.510       0.06\n",
       "5662          1       0.555      0.365       0.08\n",
       "5663          1       0.610      0.330       0.06\n",
       "5664          1       0.910      0.070       0.02\n",
       "5665          1       0.860      0.100       0.04\n",
       "5666          1       0.900      0.090       0.01\n",
       "5667          1       0.890      0.070       0.04\n",
       "5668          1       0.880      0.100       0.02"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('prediction_score.csv')\n",
    "dataframe.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5669\n",
      "AUC per aspect:\t Calls, CustomerService, Data, General, Network\n",
      "[0.7006989083939131, 0.6694798642326392, 0.6745171515701973, 0.7540231330148354, 0.6692446245637735]\n",
      "{'aspect_strict_Acc': 0.23654015887025595, 'aspect_Macro_F1': 0.08959557259358601, 'aspect_Macro_AUC': 0.6935927363550716, 'sentiment_Acc': 0.9651406971860563, 'sentiment_Macro_AUC': 0.8196489813725861}\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Oct 20 11:40:28 2019\n",
    "\n",
    "@author: David\n",
    "\"\"\"\n",
    "\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "\n",
    "def get_y_true():\n",
    "#    \"\"\" \n",
    "#    Read file to obtain y_true.\n",
    "#        \n",
    "#    \"\"\"\n",
    "    true_data_file = \"D:/jupyter/Year2_Research/Generate_Data/data/5_aspects/test_NLI.tsv\"\n",
    "\n",
    "    df = pd.read_csv(true_data_file,sep='\\t')\n",
    "    y_true = []\n",
    "    for i in range(len(df)):\n",
    "        label = df['label'][i]\n",
    "        assert label in ['None', 'Positive', 'Negative'], \"error!\"\n",
    "        if label == 'None':\n",
    "            n = 1\n",
    "        elif label == 'Positive':\n",
    "            n = 2\n",
    "        else:\n",
    "            n = 0\n",
    "        y_true.append(n)\n",
    "\n",
    "    print(len(y_true))   \n",
    "    return y_true\n",
    "\n",
    "        \n",
    "def get_y_pred():\n",
    "#    \"\"\" \n",
    "#    Read file to obtain y_pred and scores.\n",
    "#    \"\"\"\n",
    "               \n",
    "    dataframe = pd.read_csv('prediction_score.csv')\n",
    "    \n",
    "    pred=[]\n",
    "    score=[]\n",
    "\n",
    "\n",
    "\n",
    "    for f in range(len(dataframe)):\n",
    "        pred.append(dataframe.predicted[f])\n",
    "        score.append([float(dataframe.score_pos[f]),float(dataframe.score_none[f]),float(dataframe.score_neg[f])])\n",
    "                 \n",
    "    return pred, score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _strict_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate \"strict Acc\" of aspect detection task.\n",
    "    \"\"\"\n",
    "    total_cases=int(len(y_true)/5)\n",
    "    true_cases=0\n",
    "    for i in range(total_cases):\n",
    "        if y_true[i*5]!=y_pred[i*5]:continue\n",
    "        if y_true[i*5+1]!=y_pred[i*5+1]:continue\n",
    "        if y_true[i*5+2]!=y_pred[i*5+2]:continue\n",
    "        if y_true[i*5+3]!=y_pred[i*5+3]:continue\n",
    "        if y_true[i*5+4]!=y_pred[i*5+4]:continue\n",
    "        true_cases+=1\n",
    "    aspect_strict_Acc = true_cases/total_cases\n",
    "\n",
    "    return aspect_strict_Acc\n",
    "\n",
    "\n",
    "def _macro_F1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate \"Macro-F1\" of aspect detection task.\n",
    "    \"\"\"\n",
    "    p_all=0\n",
    "    r_all=0\n",
    "    count=0\n",
    "    for i in range(len(y_pred)//5):\n",
    "        a=set()\n",
    "        b=set()\n",
    "        for j in range(5):\n",
    "            if y_pred[i*5+j]!=1:\n",
    "                a.add(j)\n",
    "            if y_true[i*5+j]!=1:\n",
    "                b.add(j)\n",
    "        if len(b)==0:continue\n",
    "        a_b=a.intersection(b)\n",
    "        if len(a_b)>0:\n",
    "            p=len(a_b)/len(a)\n",
    "            r=len(a_b)/len(b)\n",
    "        else:\n",
    "            p=0\n",
    "            r=0\n",
    "        count+=1\n",
    "        p_all+=p\n",
    "        r_all+=r\n",
    "    Ma_p=p_all/count\n",
    "    Ma_r=r_all/count\n",
    "    aspect_Macro_F1 = 2*Ma_p*Ma_r/(Ma_p+Ma_r)\n",
    "\n",
    "    return aspect_Macro_F1\n",
    "\n",
    "\n",
    "def _AUC_Acc(y_true, score):\n",
    "    \"\"\"\n",
    "    Calculate \"Macro-AUC\" of both aspect detection and sentiment classification tasks.\n",
    "    Calculate \"Acc\" of sentiment classification task.\n",
    "    \"\"\"\n",
    "    # aspect-Macro-AUC\n",
    "    aspect_y_true=[]\n",
    "    aspect_y_score=[]\n",
    "    aspect_y_trues=[[],[],[],[],[]]\n",
    "    aspect_y_scores=[[],[],[],[],[]]\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i]>0:\n",
    "            aspect_y_true.append(0)\n",
    "        else:\n",
    "            aspect_y_true.append(1) # \"None\": 1\n",
    "        tmp_score=score[i][0] # probability of \"None\"\n",
    "        aspect_y_score.append(tmp_score)\n",
    "        aspect_y_trues[i%5].append(aspect_y_true[-1])\n",
    "        aspect_y_scores[i%5].append(aspect_y_score[-1])\n",
    "\n",
    "    aspect_auc=[]\n",
    "    for i in range(5):\n",
    "        aspect_auc.append(metrics.roc_auc_score(aspect_y_trues[i], aspect_y_scores[i]))\n",
    "        \n",
    "    print(\"AUC per aspect:\\t Calls, CustomerService, Data, General, Network\")\n",
    "    print(aspect_auc)\n",
    "    \n",
    "    aspect_Macro_AUC = np.mean(aspect_auc)\n",
    "    \n",
    "    # sentiment-Macro-AUC\n",
    "    sentiment_y_true=[]\n",
    "    sentiment_y_pred=[]\n",
    "    sentiment_y_score=[]\n",
    "    sentiment_y_trues=[[],[],[],[],[]]\n",
    "    sentiment_y_scores=[[],[],[],[],[]]\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i]>0:\n",
    "            sentiment_y_true.append(y_true[i]-1) # \"Postive\":0, \"Negative\":1\n",
    "            tmp_score=score[i][2]/(score[i][1]+score[i][2])  # probability of \"Negative\"\n",
    "            sentiment_y_score.append(tmp_score)\n",
    "            if tmp_score>0.5:\n",
    "                sentiment_y_pred.append(1) # \"Negative\": 1\n",
    "            else:\n",
    "                sentiment_y_pred.append(0)\n",
    "            sentiment_y_trues[i%5].append(sentiment_y_true[-1])\n",
    "            sentiment_y_scores[i%5].append(sentiment_y_score[-1])\n",
    "\n",
    "    sentiment_auc=[]\n",
    "    for i in range(5):\n",
    "        sentiment_auc.append(metrics.roc_auc_score(sentiment_y_trues[i], sentiment_y_scores[i]))\n",
    "    sentiment_Macro_AUC = np.mean(sentiment_auc)\n",
    "\n",
    "    # sentiment Acc\n",
    "    sentiment_y_true = np.array(sentiment_y_true)\n",
    "    sentiment_y_pred = np.array(sentiment_y_pred)\n",
    "    sentiment_Acc = metrics.accuracy_score(sentiment_y_true,sentiment_y_pred)\n",
    "\n",
    "    return aspect_Macro_AUC, sentiment_Acc, sentiment_Macro_AUC\n",
    "\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "y_true = (get_y_true())\n",
    "y_pred, score = get_y_pred()\n",
    "\n",
    "result = collections.OrderedDict()\n",
    "\n",
    "aspect_strict_Acc = _strict_acc(y_true, y_pred)\n",
    "aspect_Macro_F1 = _macro_F1(y_true, y_pred)\n",
    "aspect_Macro_AUC, sentiment_Acc, sentiment_Macro_AUC = _AUC_Acc(y_true, score)\n",
    "result = {'aspect_strict_Acc': aspect_strict_Acc,\n",
    "                'aspect_Macro_F1': aspect_Macro_F1,\n",
    "                'aspect_Macro_AUC': aspect_Macro_AUC,\n",
    "                'sentiment_Acc': sentiment_Acc,\n",
    "                'sentiment_Macro_AUC': sentiment_Macro_AUC}\n",
    "\n",
    "\n",
    "print(result)\n",
    "\n",
    "nameHandle = open('RF_word2vec_evaluation_results.txt', 'w')\n",
    "\n",
    "nameHandle.write('aspect_strict_Acc:\\t'+ str(aspect_strict_Acc))\n",
    "nameHandle.write('\\naspect_Macro_F1:\\t' + str(aspect_Macro_F1))\n",
    "nameHandle.write('\\naspect_Macro_AUC:\\t' + str(aspect_Macro_AUC))\n",
    "nameHandle.write('\\n\\nsentiment_Acc:\\t' + str(sentiment_Acc))\n",
    "nameHandle.write('\\nsentiment_Macro_AUC:\\t' + str(sentiment_Macro_AUC))\n",
    "nameHandle.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
